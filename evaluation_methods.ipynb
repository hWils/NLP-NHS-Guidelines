{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##### RESOURCES #####\n",
    "# REST API description: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/reference\n",
    "# Quotas and request limits: https://learn.microsoft.com/en-us/azure/cognitive-services/openai/quotas-limits\n",
    "# pricing: https://azure.microsoft.com/de-de/pricing/details/cognitive-services/openai-service/\n",
    "# pricing calculator: https://azure.microsoft.com/de-de/pricing/calculator\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from readability import Readability\n",
    "import textstat\n",
    "import nltk\n",
    "from bert_score import score\n",
    "from IPython.display import display, HTML\n",
    "import webbrowser\n",
    "import markdown\n",
    "import logging\n",
    "from pprint import pprint\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import openai\n",
    "from difflib import SequenceMatcher\n",
    "import spacy\n",
    "import re\n",
    "import mammoth\n",
    "from nltk.stem import PorterStemmer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API parameters for aws-comprehend and openai-gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup aws comprehend api\n",
    "endpoint_url = 'https://comprehend.eu-west-2.amazonaws.com'\n",
    "s3_client = boto3.client('comprehend', region_name='eu-west-2')#,endpoint_url=endpoint_url)\n",
    "medical_client = boto3.client(service_name='comprehendmedical',  region_name='eu-west-2')#,endpoint_url=endpoint_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_dotenv()\n",
    "\n",
    "openai.api_key = os.environ.get('OPENAI_API_KEY')\n",
    "openai.organization = 'org-WD3x2XVqrr4UO8u1zjuYSyXZ' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Methodology\n",
    "Methods for entity, keyphrase checking, similarity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_missing(string_list, target_string):\n",
    "    missing_strings = []\n",
    "    for string in string_list:\n",
    "        if string not in target_string:\n",
    "            missing_strings.append(string)\n",
    "    return missing_strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_stems(text):\n",
    "    # Tokenize the input text into individual words\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Initialize the PorterStemmer\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "    # Stem each word in the text\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Reconstruct the stemmed words back into a string\n",
    "    stemmed_text = \" \".join(stemmed_words)\n",
    "\n",
    "    return stemmed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_alphanumeric(text):\n",
    "    # Define a regular expression pattern to match non-alphanumeric characters (letters, numbers, and % sign)\n",
    "    pattern = r'[^a-zA-Z0-9\\s.%]+'\n",
    "\n",
    "    # Use re.sub() to replace the matching pattern with an empty string\n",
    "    cleaned_text = re.sub(pattern, '', text)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this uses amazon comprehend to check that entities are retained in the improved versionbb\n",
    "def standard_entity_check(text):\n",
    "    print(\"Checking this text for entities: \", text)\n",
    "    entity_text = []\n",
    "    print(\"Detecting  general entities.\")\n",
    "   # response = medical_client.detect_entities_v2(Text=text)#, LanguageCode='en')\n",
    "    response = s3_client.detect_entities(Text=text, LanguageCode='en')\n",
    "    entities = response['Entities']\n",
    "    print(entities)\n",
    "    for entity in entities:\n",
    "       # print(f'Type: {entity[\"Type\"]}, Text: {entity[\"Text\"]}')\n",
    "        entity_text.append(entity[\"Text\"].lower()) #make sure decapitalised\n",
    "    return entity_text, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medical Named Entity and Relationship Extraction (NERe)\n",
    "# this uses amazon comprehend to check that entities are retained in the improved versionbb\n",
    "def medical_entity_check(text):\n",
    "    print(\"Checking this text for entities: \", text)\n",
    "    entity_text = []\n",
    "    print(\"Detecting medical entities.\")\n",
    "    response = medical_client.detect_entities_v2(Text=text)\n",
    "    entities = response['Entities']\n",
    "  #  print(entities)\n",
    "    for entity in entities:\n",
    "        print(f'Type: {entity[\"Type\"]}, Text: {entity[\"Text\"]}')\n",
    "        entity_text.append(entity[\"Text\"].lower()) #make sure decapitalised\n",
    "    return entity_text, entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extact_all_entities(text):\n",
    "     standard_ent_text, standard_entities = standard_entity_check(text)\n",
    "     print(\"Standard entities \", standard_ent_text)\n",
    "     med_ent_text, med_entities = medical_entity_check(text)\n",
    "     print(\"Medical entities \", med_ent_text)\n",
    "     all_entities = standard_ent_text + med_ent_text\n",
    "     return all_entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat(entity_list):\n",
    "    entity_list = list(map(remove_non_alphanumeric, entity_list))\n",
    "    entity_list = list(map(str.lower, entity_list))\n",
    "    entity_list = list(map(remove_stems, entity_list))\n",
    "    return entity_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_strings_not_in_text(main_text, string_list):\n",
    "    strings_not_in_text = []\n",
    "    \n",
    "    for string in string_list:\n",
    "        if string not in main_text:\n",
    "            strings_not_in_text.append(string)\n",
    "    \n",
    "    return strings_not_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_entities(original, new):\n",
    "    all_ori_entities = extact_all_entities(original)\n",
    "    all_new_entities = extact_all_entities(new)\n",
    "    \n",
    "    # process entities to remove stems, capitalisation and grammatical symbols\n",
    "    all_ori_entities = reformat(all_ori_entities)\n",
    "    all_new_entities = reformat(all_new_entities)\n",
    "\n",
    "    \n",
    "    original_text = remove_non_alphanumeric(original.lower())\n",
    "    original_text = remove_stems(original_text)\n",
    "\n",
    "    new_text = remove_non_alphanumeric(new.lower())\n",
    "    new_text = remove_stems(new_text)\n",
    "\n",
    "\n",
    "   # missing = find_missing(new_text, all_ori_entities) \n",
    "    missing = find_strings_not_in_text(new_text, all_new_entities)\n",
    "    print(\"OLD\", all_ori_entities)\n",
    "    print(\"NEW\", all_ori_entities)\n",
    "   # extra = find_missing(all_new_entities, all_ori_entities)\n",
    "    extra = find_strings_not_in_text(original_text, all_new_entities)\n",
    "    return all_ori_entities, all_new_entities, missing, extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to increase the max tokens\n",
    "def generate_relations(section, entities):\n",
    "    print(\"GENERATING\")\n",
    "    prompt = 'Given the following text, and entities. Generate the relations of these entities and provide this as a list. '+  section +  entities\n",
    "    gpt_policy = openai.Completion.create(model=\"text-davinci-003\", prompt=prompt, max_tokens=3000)\n",
    "   # print(gpt_policy)\n",
    "    text = gpt_policy['choices'][0]['text']\n",
    "    print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Key phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_key_phrases(text):\n",
    "    response = s3_client.detect_key_phrases(Text=text, LanguageCode='en')\n",
    "    key_phrases = [phrase['Text'] for phrase in response['KeyPhrases']]\n",
    "    return key_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_keyphrases(original, new):\n",
    "    all_ori_kp = extract_key_phrases(original)\n",
    "    all_new_kp = extract_key_phrases(new)\n",
    "    missing = find_missing(all_ori_kp, all_new_kp)\n",
    "    extra = find_missing(new, all_new_kp)\n",
    "    return all_ori_kp, all_new_kp, missing, extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can be used to capture element/character similarity but not semantic\n",
    "def similarity(entity1, entity2):\n",
    "    # Calculate similarity ratio between two entities or keyphrases\n",
    "    return SequenceMatcher(None, entity1, entity2).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_BERT(original, new):\n",
    "    P, R, F1 = score([original], [new], lang=\"en\", verbose=False)\n",
    " #   row.append(F1.item())\n",
    "    print(\"BERT F1 is \", round(F1.item()),2)\n",
    "    return round(F1.item(),2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_flesch_kincaid(text):\n",
    "    fk = textstat.flesch_kincaid_grade(text)\n",
    "    return round(fk,2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT detecting extra - hallucinatory information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original = 'ECG, blood pressure and respiratory rate continuously during administration. Reduce rate of administration if bradycardia or hypotension occurs. Cardiac resuscitation equipment should be available. Monitor injection site during and for 72 hours following administration. Therapeutic drug level monitoring is required.'\n",
    "hallucination = '**Do not infuse with any other medicines.** ECG, blood pressure and respiratory rate continuously during administration. Reduce rate of administration if bradycardia or hypotension occurs. Cardiac resuscitation equipment should be available. Monitor injection site during and for 72 hours following administration. Therapeutic drug level monitoring is required.'\n",
    "gpt_markdown = hallucination \n",
    "goldstandard = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hallucination_check(original, new):\n",
    "        prompt = '''You are a quality control expert checking whether extra meaning\n",
    "        has been added to an improved version of text generated using GPT. You check by comparing\n",
    "        the original and new text. Output 'yes' or 'no'.\n",
    "        If 'yes', then write 'extra content has been added' followed with the text which is additional content in quotes.\n",
    "        The original text: ''' + original + ' The new text: ' + new\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model = \"gpt-4-0314\",#\"gpt-4\",   # we use a fixed model to prevent updates changing how the prompts operate\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens = 2500,\n",
    "        temperature = 0 #is zero to ensure the model is deterministic as possible\n",
    "        )\n",
    "        text = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, extra content has been added: \"Do not infuse with any other medicines.\"\n"
     ]
    }
   ],
   "source": [
    "#output = hallucination_check(original,hallucination)\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main evaluation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Suitable diluents: sodium chloride 0.9% or glucose 5%.(1). Amikacin solution may darken to a pale yellow colour when diluted; this does not affect potency.(4) ',\n",
       " 'Suitable diluents: sodium chloride 0.9 % or glucose 5 %. Amikacin solution may darken to a pale yellow colour when diluted due to natural chemical reactions; however, rigorous testing ensures that these reactions do not compromise its potency.',\n",
       " 'Suitable diluents: sodium chloride 0.9 % or glucose 5 %. Amikacin solution may darken to a pale yellow colour when diluted due to natural chemical reactions; however, rigorous testing ensures that these reactions do not compromise its potency.',\n",
       " 0.95,\n",
       " 0.95,\n",
       " 0.79,\n",
       " 6.4,\n",
       " 10.3,\n",
       " 10.3,\n",
       " -3.5,\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hallucination_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluation metrics include BERT for semantic similarity; and FK\n",
    "def evaluation(original, gpt_plain, gpt_markdown,gold_standard):\n",
    "    row = []\n",
    "    if len(gpt_plain) < 1:\n",
    "        gpt_plain = 'Empty'\n",
    "    if len(gpt_markdown) < 1:\n",
    "        gpt_markdown = 'Empty'\n",
    "    if len(gold_standard) < 1:\n",
    "        gold_standard = 'Empty'\n",
    "    \n",
    "    ### CLEAN: get rid of unwanted grammar during evaluation as it impacts entity and keyphrase checks\n",
    "   # original = original.replace('\\n', '')\n",
    "   # gpt_plain = gpt_plain.replace('\\n', '')\n",
    "\n",
    "   # manual_new = manual_new.lower().replace('\\n', '')\n",
    "\n",
    "    ### BERT SCORE #######\n",
    "    print(\"###      COMPUTING BERT SCORE        ###\")\n",
    "    gs_BERT = evaluate_BERT(original, gold_standard)\n",
    "    gptplain_BERT = evaluate_BERT(original,gpt_plain)\n",
    "    markdown_BERT = evaluate_BERT(original,gpt_markdown)\n",
    "\n",
    "\n",
    "    ###  FLESCH-KINCAIRD ######\n",
    "    fk_ori = evaluate_flesch_kincaid(original)\n",
    "    fk_gpt =evaluate_flesch_kincaid(gpt_plain)\n",
    "    fk_mark =evaluate_flesch_kincaid(gpt_markdown)\n",
    "    fk_gs =evaluate_flesch_kincaid(gold_standard)\n",
    "\n",
    "        \n",
    "\n",
    "    print(\"Flesch-Kincaid Scores, Original, Plain, Markdown, goldstandard are: \", fk_ori, fk_gpt, fk_mark, fk_gs)\n",
    "  \n",
    "    ### KEY PHRASE AND ENTITY CHECKING ##### \n",
    "    all_ori_entities, all_plain_entities, plain_missing_e, plain_extra_e = evaluate_entities(original, gpt_plain)\n",
    "    all_ori_entities, all_markdown_entities, markdown_missing_e, markdown_extra_e = evaluate_entities(original, gpt_markdown)\n",
    "    all_ori_entities, all_gs_entities, gs_missing_e, gs_extra_e = evaluate_entities(original, gold_standard)\n",
    "  \n",
    "\n",
    "\n",
    " \n",
    "    ### RELATION CHECKING\n",
    "    #adapt formattings\n",
    "    all_ori_entities = \";\".join(all_ori_entities)\n",
    "    all_plain_entities = \";\".join(all_plain_entities)\n",
    "    ori_relations = generate_relations(original, all_ori_entities)\n",
    "    plain_new_relations = generate_relations(gpt_plain, all_plain_entities)\n",
    "\n",
    "\n",
    "    row.extend([original, gpt_plain, gpt_markdown])\n",
    "    row.extend([gptplain_BERT, markdown_BERT, gs_BERT])\n",
    "    row.extend([fk_ori, fk_gpt, fk_mark,fk_gs])\n",
    "    row.extend([plain_missing_e, plain_extra_e,markdown_missing_e, markdown_extra_e])\n",
    "\n",
    "    \n",
    "\n",
    "    return row"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
